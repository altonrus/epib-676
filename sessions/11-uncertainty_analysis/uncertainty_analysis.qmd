---
title: "Uncertainty analysis"
subtitle: "EPIB  676 session 11, McGill University"
author: "Alton Russell"
date: "3 Oct 2024"
format: revealjs
editor: visual
---

## Packages

```{r}
#| echo: true
library(ggplot2) #plotting
library(tidyverse)
library(dampack) #cost-effectiveness sensitivity analysis
# https://github.com/DARTH-git/dampack
library(rriskDistributions) #fit distn to quantile
theme_set(theme_bw()) #set ggplot theme
```

## Today

-   **Deterministic uncertainty analysis**

-   Probabilistic sensitivity analysis

## Decision-analytic model as function

-   Function mapping inputs (data, parameters) into estimated outcomes for two or more alternatives
-   Propagate uncertainty
    -   Uncertain inputs â†’ uncertain outputs

![](figs/model-inputs-outputs.svg)

## Three types of uncertainty

-   **First order** **(stochastic):** variation between statistically identical patients

-   **Second order (parameter):** uncertainty in a population parameter

-   **Third order (structural):** uncertainty in relation between parameters enforced by model

## Three types of uncertainty

-   **First order** **(stochastic):** variation between statistically identical patients

    -   Eliminate (run enough simulations to make negligible)

-   **Second order (parameter):** uncertainty in a population parameter

    -   Estimate using **p[arametric sensitivity analysis]{.underline}**

-   **Third order (structural):** uncertainty in relation between parameters

    -   Estimate using [**structural sensitivity analysis**]{.underline}

## Uncertainty analysis types

Changing inputs/parameters

-   **Univariate:** vary 1 parameter over a range

-   **Multivariate:** vary \>1 parameter over a range

-   **Scenario:** set 1 or more parameters to alternative value

-   **Probabilistic:** sample uncertain parameters from distributions (and/or bootstrap input data)

Changing model

-   **Structural:** scenario analysis with a different functional form (e.g., altered causal relationship between parameters)

## Toy model: death-averting treatment decision tree

```{r}
#| echo: true

#base case parameters
l_prms <- list(cost_treat = 60000,      prob_death_noTreat = .3,
               rr_death_drug = 0.5,     QALY_survive = 12,
               cost_survive = 12000)

model <- function(l_prms){
  tot_cost_noTreat = (1-l_prms$prob_death_noTreat)*l_prms$cost_survive
  tot_cost_treat = (l_prms$cost_treat + 
                    (1-l_prms$prob_death_noTreat*l_prms$rr_death_drug)*
                    l_prms$cost_survive)
  tot_QALY_noTreat = (1-l_prms$prob_death_noTreat)*l_prms$QALY_survive
  tot_QALY_treat = (1-l_prms$prob_death_noTreat*l_prms$rr_death_drug)*
                   l_prms$QALY_survive
  return(list(tot_cost_noTreat=tot_cost_noTreat,  tot_cost_treat=tot_cost_treat,
              tot_QALY_noTreat=tot_QALY_noTreat,  tot_QALY_treat=tot_QALY_treat,
             ICER_treat = (tot_cost_treat - tot_cost_noTreat)/
               (tot_QALY_treat - tot_QALY_noTreat)))
}
```

## Base case results

All parameters at their expected value.

```{r}
#| echo: true
l_basecase_results <- model(l_prms); l_basecase_results
```

## One way sensitivity analysis

-   Define the **minimum** and **maximum** plausible value for an uncertain parameter

    -   Sometimes based on 95% confidence interval from a study or meta-analysis

-   Change the parameter value along the range

-   Observe change in the output

## Ex: One way sensitivity analysis

```{r}
#| echo: true
rr_drug_min = 0.2; rr_drug_max = 0.6; l_prms_temp <- l_prms
l_prms_temp[["rr_death_drug"]] <- rr_drug_min #Min value
result_rr_drug_min = model(l_prms_temp)
l_prms_temp[["rr_death_drug"]] <- rr_drug_max #Max value
result_rr_drug_max = model(l_prms_temp)
```

::::: columns
::: {.column width="50%"}
Min rr death with drug

```{r}
result_rr_drug_min
```
:::

::: {.column width="50%"}
Max rr of death with drug

```{r}
result_rr_drug_max
```
:::
:::::

## Note on one-way sensitivity analysis

-   Usually, monotonic relationship between parameters and outcomes

    -   As parameter $\uparrow$, outcome $\uparrow$, or

    -   As parameter $\uparrow$, outcome $\downarrow$

-   If you know it's monotonic, can just run the max, min, and basecase values

-   If any doubt, check several points and plot

## OWSA plot: single input parameter

```{r}
#| echo: true
t_rr_drug_owsa <- data.frame(
  rr_death_drug = seq(from=rr_drug_min, to=rr_drug_max, length.out=20),
  ICER_treat = 0)
for (row in 1:nrow(t_rr_drug_owsa)){
  l_prms_temp <- l_prms
  l_prms_temp[["rr_death_drug"]] <- t_rr_drug_owsa[row, "rr_death_drug"]
  t_rr_drug_owsa[row, "ICER_treat"] <- model(l_prms_temp)$ICER_treat}
ggplot(data=t_rr_drug_owsa, aes(x=rr_death_drug, y=ICER_treat))+
  geom_point()+geom_line()
```

## OWSA on all input parameters

All uncertain parameters assigned min and max value

```{r}
#| echo: true
t_owsa <- data.frame(
  name = names(l_prms),
  value = unname(unlist(l_prms)),
  value.min = c(30000, .16, .2, 9, 8000),
  value.max = c(100000, .45, .6, 16, 16000),
  ICER.min = 0,  ICER.max = 0)

t_owsa
```

## OWSA on all input parameters

Loop over parameters, calculate outcome at min and max value

```{r}
#| echo: true
for (row in 1:nrow(t_owsa)){
  l_prms_temp <- l_prms # Reset to base case value (IMPORTANT!!!!)
  # Calculate ICER with parameter at min value
  l_prms_temp[[t_owsa[row,"name"]]] <- t_owsa[row,"value.min"]
  t_owsa[row, "ICER.min"] <- model(l_prms_temp)$ICER_treat
  # Calculate ICER with parameter at max value
  l_prms_temp[[t_owsa[row,"name"]]] <- t_owsa[row,"value.max"]
  t_owsa[row, "ICER.max"] <- model(l_prms_temp)$ICER_treat
}
# Add column for range of the ICER (absolute value)
t_owsa$ICER.range <- abs(t_owsa$ICER.max - t_owsa$ICER.min); t_owsa
```

## Tornado diagram code

Vertical line at base case result (**black**) and decision threshold (**red**). Conclusion is sensitive to parameter whose bar crosses decision threshold.

```{r}
#| echo: true
p_tornado <- ggplot(data = t_owsa) +
  geom_segment(aes(x = reorder(name, ICER.range), #biggest to smallest ICER range
                   xend=reorder(name, ICER.range), 
                   y = ICER.min, 
                   yend=ICER.max), size=6, color="grey")+
  theme(legend.position = "None")+
  coord_flip()+
  geom_hline(yintercept = l_basecase_results$ICER_treat, color="black")+
  geom_hline(yintercept = 50000, alpha = 0.5, color = "red")+
  scale_alpha_manual(values = c(1, 0))+
  scale_y_continuous(labels = function(x){paste0("$",x/1e3,"K")},
                     )+
  xlab("")+
  ylab("ICER of treatment vs. no treatment")
```

## Tornado diagram

```{r}
#| echo: true
p_tornado
```

## Example tornado: Is pathogen inactivation in Ghana cost-saving?

![](figs/wbpr_ghana_tornado.png)

## OWSA for \>2 policies?

::::: columns
::: {.column width="65%"}
![](figs/zika_owsa.png)
:::

::: {.column width="35%"}
-   One approach

-   X-axis: changing parameter value two standard deviations from mean

-   Parameter value at base case and thresholds for change in preferred strategy in red text.
:::
:::::

## Two way sensitivity analysis (TWSA)

Simultaneously change a [**pair**]{.underline} of parameters over plausible range

```{r}
#| echo: true
# Make grid with each of 20 possible values for each parameter
rr_death_drug = seq(from=rr_drug_min, to=rr_drug_max, length.out=20)
prob_death_noTreat = seq(from=.16, to=.45, length.out=20)

t_twoway <- expand.grid(rr_death_drug=rr_death_drug, 
                        prob_death_noTreat=prob_death_noTreat)

# Add column for the ICER
t_twoway$ICER <- 0

head(t_twoway)
```

## Two way sensitivity analysis (TWSA)

Simultaneously change a [**pair**]{.underline} of parameters over plausible range

```{r}
#| echo: true
# Run model & save ICER for each combo of the parameters
l_prms_temp <- l_prms

for (row in 1:nrow(t_twoway)){
  l_prms_temp[["rr_death_drug"]] <- t_twoway[row,"rr_death_drug"]
  l_prms_temp[["prob_death_noTreat"]] <- t_twoway[row,"prob_death_noTreat"]
  t_twoway[row,"ICER"] <- model(l_prms_temp)$ICER_treat}
head(t_twoway)
```

## TWSA plot of continuous outcome (ICER)

```{r}
#| echo: true
ggplot(data=t_twoway, aes(x=rr_death_drug, y=prob_death_noTreat, fill=ICER)) +
  geom_tile() +scale_fill_gradientn(colors=c("blue","red"))
```

## TWSA plot of preferred policy

```{r}
#| echo: true
# Apply willingness-to-pay theshold to find preferred strategy
t_twoway$preferred <- ifelse(t_twoway$ICER > 50000, "Do not treat", "Treat")
# Plot
ggplot(data=t_twoway, aes(x=rr_death_drug, y=prob_death_noTreat, fill=preferred)) +
  geom_tile()
```

## Complex Example

::::: columns
::: {.column width="45%"}
![](figs/blood_safety_portfoloi_WTP_scenarios.png)
:::

::: {.column width="55%"}
![](figs/outcomes_by_prevalence.png)
:::
:::::

## 3-way sensitivity analysis example

[![Cost analysis of mobile health TB contact investigation, Turimumahoro et. al. 2022](figs/three_way_sens_analysis_TB_mHealth.png)](https://doi.org/10.1371/journal.pone.0265033)

## Scenario analysis

-   Can also construct "scenarios" corresponding to possible parameter regimes

-   Useful for:

    -   Design parameters (discount rate, time horizon, perspective)

    -   Scenarios defined by \>1 parameter

    -   Example:

        -   Omicron wave: $\uparrow$ infectivity and $\downarrow$ vaccine efficacy

        -   Canadian analysis with US cost scenario (resource costs sourced from USA

-   Scenario analyses are often deterministic, but you can do PSA within a scenario

## Today

-   Deterministic uncertainty analysis

-   **Probabilistic sensitivity analysis (PSA)**

## Limits of deterministic uncertainty analysis

-   Lots of uncertain parameters

-   Hard to visualize varying \>2

-   Deterministic methods ignore fact that all values in parameter's plausible range are not equally likely

**Want to know:** how certain are our results given [**all**]{.underline} the uncertainty in [**all**]{.underline} parameters?

## Recall: uncertainty in Bayesian terms

::::: columns
::: {.column width="70%"}
![](figs/sampling_dists_posterior_statisticalRethinking.png)
:::

::: {.column width="30%"}
**Posterior** $\rightarrow$ parameter uncertainty

**Sampling distn** $\rightarrow$ stochastic uncertainty

**Posterior predictive distn** $\rightarrow$ uncertainty in outcomes
:::
:::::

## Basic PSA procedure

1.  Assign distribution to uncertain parameters (or bootstrap from individual-level data)

2.  Sample N input parameter sets (often 5-10,000)

3.  Run model and calculate outcomes for each parameter set

From the output, you can:

-   Report quantile-based credible intervals:

    -   *20 (95% CrI 17 to 22) adverse events averted*

-   Make probabilistic statements:

    -   *Treatment was cost-effective in 87% of iterations*

## Common PSA distributions

| Parameter type                      | Range          | Dist'n(s)        |
|-------------------------------------|----------------|------------------|
| Probability                         | \[0,1\]        | Beta             |
| Relative risk                       | \[0,$\infty$\] | lognormal        |
| Variable cost (e.g., hospital stay) | \[0,$\infty$\] | gamma, lognormal |
| Unit cost (e.g., medicine)          | \[0,$\infty$\] | gamma, normal    |
| Utility                             | \[0,1\]\*      | beta             |

\*mostly

## High uncertainty distributions

![](figs/distn_high_uncertainty.png)

Mainly used when 'expert opinion' is main data source

[**Remember**]{.underline}: We want experts' estimate of uncertainty in parameter mean, not individual-level variance

## Multi-outcome probabilities

-   Probability of each branches from decision tree node (or transitions from Markov state) must sum to 1

-   2 outcomes: no problem. Sample P(A), set P(B) = 1 - P(A)

-   \>2 outcomes but most small proability: Can calculate P(big) as 1 - sum(P(smalls)), might be OK

What if \>2 outcomes are possible and plausible?

## Dirichlet: beta for multi-outcome probabilities

::::: columns
::: {.column width="60%"}
-   $\alpha_C$ parameters corespond to possible outcomes $1,2,..,C$

-   $E[P[c]] = \alpha_c/\sum_1^C \alpha_i$

-   The larger $\sum_1^C \alpha_i$, the greater the precision
:::

::: {.column width="40%"}
![](figs/Dirichlet_tri.png)
:::
:::::

## Where Dirichlet is used for PSA?

-   Each row of a transition matrix

    -   Probability of transitioning out of state must sum to 1

-   Each branch from a decision node

    -   Probability of each branch must sum to 1

## PSA example: our toy model

```{r}
#| echo: true
t_owsa
```

\br

**Goal:** fit distribution to each parameter. Use `value.min` and `value.max` as `.025` and `.975` quantile and the base case value as the mean.

## Ex: fitting distns (rriskDistributions)

```{r}
#| echo: true
#| output: false
n=1000
cost_treat_lnorm <- get.lnorm.par(q=c(3000, 6000, 10000))
v_psa_cost_treat <- rlnorm(n, meanlog = cost_treat_lnorm[["meanlog"]],
                           sdlog = cost_treat_lnorm[["sdlog"]])
prob_death_noTreat_beta <- get.beta.par(q=c(.16, .3, .45))
v_psa_prob_death_noTreat <- rbeta(n, shape1=prob_death_noTreat_beta[["shape1"]],
                              shape2=prob_death_noTreat_beta[["shape2"]])
rr_death_drug_lnorm <- get.lnorm.par(q=c(.2, .5, .6))
v_psa_rr_death_drug <- rlnorm(n, meanlog = rr_death_drug_lnorm[["meanlog"]],
                           sdlog = rr_death_drug_lnorm[["sdlog"]])
QALY_survive_norm <- get.norm.par(q=c(9, 12, 16))
v_psa_QALY_survive <- rnorm(n, mean=QALY_survive_norm[["mean"]],
                        sd = QALY_survive_norm[["sd"]])
cost_survive_lnorm <- get.lnorm.par(q=c(8000, 12000, 16000))
v_psa_cost_survive <- rlnorm(n, meanlog=cost_survive_lnorm[["meanlog"]],
                         sdlog = cost_survive_lnorm[["sdlog"]])
```

## Note

The [**expected value (mean)**]{.underline} of a PSA distribution should be the base case value. For asymmetric distributions, median will not equal the mean. To simplify this in-class example, I set the base case value as the median.

In assignment four, I provide functions to fit a distribution to the mean and two quantiles (e.g., 0.025 and 0.975 percentile)

## Ex: run model for each PSA input set

```{r}
#| echo: true
t_psa <- data.frame(
  cost_treat = v_psa_cost_treat,
  prob_death_noTreat = v_psa_prob_death_noTreat,
  rr_death_drug = v_psa_rr_death_drug,
  QALY_survive = v_psa_QALY_survive,
  cost_survive = v_psa_cost_survive)
l_prm_temp <- as.list(t_psa[row,])
psa_output <- data.frame(model(l_prm_temp))
for (row in 2:nrow(t_psa)){
  l_prm_temp <- as.list(t_psa[row,])
  psa_output <- rbind(psa_output, data.frame(model(l_prm_temp)))
}
t_psa <- cbind(t_psa, psa_output); head(t_psa, 3)
```

## DAMPACK package

Great for

-   Cost-effectiveness calculations and plotting

    -   `vignette("basic_cea", package = "dampack")`

-   Probabilistics Sensitivity analysis

    -   `vignette("psa_analysis", package = "dampack")`

-   ...and more

    -   See [github repo](https://github.com/DARTH-git/dampack) or [DARTH working group](https://darthworkgroup.com/) website

## PSA with DAMPACK

```{r}
#| echo: true
data("example_psa") # creates a named list "example_psa"
example_psa$strategies
head(example_psa$cost, 3)
head(example_psa$effectiveness,3)
str(example_psa$parameters)
```

## DAMPACK: make a PSA object

```{r}
#| echo: true
psa_obj <- make_psa_obj(
  cost=example_psa$cost,#col= tot cost by strategy, row=PSA iteration
  effectiveness=example_psa$effectiveness,#col=effectiveness(QALY) by strategy
  parameters=example_psa$parameters,#col=parameter, row=PSA iteration
  strategies=example_psa$strategies,#vector of strings, names of strategies
  currency="$")

summary(psa_obj, calc_sds=T)
```

## PSA scatter plot

```{r}
#| echo: true
plot(psa_obj)
```

## Preferred strategy by WTP level

-   Can determine preferred strategy with incremental analysis for each PSA iteration at each willingness-to-pay level with nested loops, like assignment 1, but [**inefficient**]{.underline}

-   Instead, calculate [**net monetary benefit**]{.underline} at each WTP level for each strategy in each PSA iteration

    -   Easy to vectorize (more efficient)

    -   Strategy with maximum NMB in given PSA iteration is preferred

## Recall: net monetary benefit

-   ICER not ideal in some contexts: negative ICERs are ambiguous; ratios are unstable with small denominators; incremental analysis requires loops

-   Net Monetary Benefit uses WTP to monetize health benefits:

$$
NMB_a = \bar{e}_a\times WTP - \bar{c}_a
$$

-   $NMB_a \geq NMB_b \Leftrightarrow ICER_{\text{\{a vs. b\}}} \leq WTP$, both imply that $a$ is preferred (cost-effective) compared to $b$

## Visualization of net monetary benefit vs. willingness-to-pay

![](figs/NMB_plot_assign1.png)

## Cost-effectiveness acceptability curve

[**Probability**]{.underline} the intervention is preferred for a given willingness-to-pay level is estimated using the [**proportion of PSA iterations**]{.underline} in which the intervention is preferred

```{r}
#| echo: true
ceac_obj <- ceac(wtp = seq(from=0, to=150000, by=10000), 
                 psa = psa_obj)
head(ceac_obj)
```

## Cost-effectiveness acceptability curve

```{r}
#| echo: true
p_ceac <- plot(ceac_obj)+ylab("Pr Most Cost-Effective"); p_ceac
```

## Cost-effectiveness acceptability curve

-   X-axis: willingness-to-pay thresholds

-   Y-axis: estimated probability intervention preferred (most cost-effective) given WTP

-   **Frontier**: intervention with the greatest expected NMB

    -   Optimal strategy is one that maximizes expected NMB
    -   Sometimes different from strategy with the greatest probability of being preferred

## More on frontier

For a WTP, intervention with the greatest probability of cost-effectiveness may not be the intervention with the greatest expected NMB

::::: columns
::: {.column width="60%"}
For PSA data on the right

-   Which intervention has the greater probability of cost-effective?

-   Which intervention has the greater expected NMB?
:::

::: {.column width="40%"}
```{r}
psa_nmb <- tibble(
  psa_iter = 1:4,
  NMB_A = c(5,6,9,25),
  NMB_B = c(4,7,8,3)
)
psa_nmb
```
:::
:::::

## More on frontier

For a WTP, intervention with the greatest probability of cost-effectiveness may not be the intervention with the greatest expected NMB

```{r}
#| echo: true
# Estimated probability A is preferred
psa_nmb <- psa_nmb |>
  mutate(A_preferred = NMB_A > NMB_B)
mean(psa_nmb$A_preferred)

# Intervention maximizing expected NMB (on the 'frontier')
mean(psa_nmb$NMB_A)
mean(psa_nmb$NMB_B)

```

## CEAC with Pr(cost-effective) on Y axis

Compares all policies to a "status quo" (does not consider incremental analysis/dominance)

![](figs/CEAC_breast_cancer_drug.png)

## Expected loss curve

Expected loss = expected net monitary benefit foregone by choosing less-than-optimal intervention

```{r}
#| echo: true
el <- calc_exp_loss(wtp = seq(from=0, to=150000, by=10000), 
                    psa = psa_obj)
plot(el, n_x_ticks = 8, n_y_ticks = 6)
```

## Which parameters to vary in PSA?

-   **Parameters estimated with uncertainty** should all be varied in PSA

-   **Design parameters** like discount rate, time horizon can be analyzed in scenario analysis

## Credible intervals from PSA output

-   Define X% credible interval as the range between the \[(1-X%)/2, 1-(1-X%)/2\] percentile of outcomes (or inputs) from PSA iterations

-   E.g, 95% CrI: (2.5 %ile to 97.5 %ile)

```{r}
#| echo: true
sapply(t_psa, function(x) paste0(round(mean(x),2), " (95% CrI ",
                                round(quantile(x, p=.025),2)," to ",
                                round(quantile(x, p=.975),2), ")"))

```

## PSA and correlation

-   In principle, inputs to PSA should be sampled from the joint probability distribution of all uncertain parameters (accounting for correlation)

-   In practice, we often treat PSA inputs as independent

    -   Probably overestimates uncertainty in most cases
    -   Should try to account for correlation between parameters when it's likely to matter

## Corr 1: multivariate distn

Can fit multivariate distributions to data

-   Normal and lognormal are easiest

-   [Fairley et. al. 2021](https://www.doi.org/10.1001/jamapsychiatry.2021.0247) fit a multivariate log-normal distribution to many parameters to capture correlation between values by policy (see supplement)

![](figs/fairly_multivariate_ex.png)

## Corr 2: relative parameters

-   Defining some parameters relative to others can enforce certain relationships

-   Ex: absolute parameters:

    -   P(death no naloxone): 0.3 (0.2 to 0.4)

    -   P(death with naloxone): 0.2 (0.1 to 0.25)

-   Ex: relative parameters

    -   P(death no naloxone): 0.3 (0.2 to 0.4)

    -   RR(death with naloxone): 0.66 (0.33 to 0.83)

-   Not perfect but easier to implement

## Bootstrapping patient-level data

-   Distribution-free method for estimating uncertainty for cohort summary statistics

    -   Sample cohort with replacement, keeping original cohort size, many times

    -   Calculate outcome on reach resample

    -   Take credible interval of each outcome across each resample

-   If directly simulating from patient dataset, use a different resampled cohort within each PSA iteration

## Bootstrapping when deriving parameters

-   [**Situation**]{.underline}: using patient-level data to estimate \>1 parameter in your model (not directly feeding patient-level data into model)

-   To preserve correlation between derived parameters in PSA

    -   Generate a bootstrap resample for each planned PSA iteration
    -   Derive parameters for each PSA iteration from a common resample

## Recap

-   Model is function mapping inputs to outputs

-   Parameteric uncertainty analysis: change inputs, observe change in outputs

    -   Deterministic (1-way, tornado diagrams, multi-way)
    -   Probabilistic (Pr(preferred), credible intervals, cost-effectiveness acceptability curves)

-   Structural: change the model itself

## Logistics

-   Assignment 3 (simulation) due tomorrow

-   Assignment 4 (sensitivity analysis) due Fri, Oct 25

-   Project proposal due Fri, Nov 1

    -   I suggest discussing your idea with me before proposal deadline

-   Presentation of open-source modelling paper in class on Tues, Nov 5
